{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5b822-74b4-4b4c-bda8-9fe30e0d1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q1. Difference between Linear and Logistic Regression\n",
    "\n",
    "#**Linear Regression**:\n",
    "#- **Purpose**: Predicts continuous outcomes.\n",
    "#- **Equation**: \\( y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_n x_n \\).\n",
    "\n",
    "#**Logistic Regression**:\n",
    "#- **Purpose**: Predicts binary outcomes (0 or 1).\n",
    "#- **Equation**: Uses the logistic function \\( \\sigma(z) = \\frac{1}{1 + e^{-z}} \\) where \\( z = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_n x_n \\).\n",
    "\n",
    "#**Example**: Logistic regression is more appropriate for predicting whether an email is spam (yes/no).\n",
    "\n",
    "### Q2. Cost Function in Logistic Regression\n",
    "#The cost function is the **log-loss** or **binary cross-entropy**:\n",
    "#It is optimized using **gradient descent**.\n",
    "\n",
    "### Q3. Regularization in Logistic Regression\n",
    "#Regularization adds a penalty term to the cost function to prevent overfitting:\n",
    "#- **L1 Regularization (Lasso)**: Adds \\( \\lambda \\sum_{j=1}^{n} |\\beta_j| \\).\n",
    "#- **L2 Regularization (Ridge)**: Adds \\( \\lambda \\sum_{j=1}^{n} \\beta_j^2 \\).\n",
    "\n",
    "### Q4. ROC Curve\n",
    "#The **ROC curve** (Receiver Operating Characteristic) plots the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. It helps evaluate model performance by assessing the trade-off between sensitivity and specificity.\n",
    "\n",
    "### Q5. Feature Selection Techniques\n",
    "#- **Recursive Feature Elimination (RFE)**.\n",
    "#- **L1 Regularization (Lasso)**.\n",
    "#- **Feature importance from tree-based methods**.\n",
    "#These techniques improve model performance by removing irrelevant or redundant features.\n",
    "\n",
    "### Q6. Handling Imbalanced Datasets\n",
    "#- **Resampling Techniques**: Oversampling the minority class or undersampling the majority class.\n",
    "#- **Synthetic Data Generation**: SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "#- **Using Different Metrics**: Precision, recall, F1-score instead of accuracy.\n",
    "\n",
    "### Q7. Common Issues in Logistic Regression\n",
    "#- **Multicollinearity**: Addressed by removing or combining correlated features, or using regularization.\n",
    "#- **Class Imbalance**: Addressed by resampling techniques, synthetic data generation, or adjusting the decision threshold.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
