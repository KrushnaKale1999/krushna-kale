{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfd20cb-519a-4fbe-819d-8a0c5fddcd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "#**Lasso Regression**: A linear regression method that includes an L1 regularization term, which adds the absolute value of coefficients to the loss function. \n",
    "#This tends to shrink some coefficients to zero, effectively performing variable selection.\n",
    "\n",
    "#**Difference from Other Techniques**: Unlike ordinary least squares (OLS) regression, which minimizes the sum of squared residuals, Lasso minimizes the sum of squared residuals plus a penalty proportional to the sum of the absolute values of the coefficients.\n",
    "\n",
    "### Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "#Lasso Regression's L1 regularization can shrink some coefficients to exactly zero, thereby performing automatic feature selection by excluding irrelevant variables.\n",
    "\n",
    "### Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "#The coefficients in Lasso Regression indicate the change in the dependent variable for a one-unit change in the predictor, similar to OLS. \n",
    "#However, Lasso may set some coefficients exactly to zero, indicating those predictors are not important in the model.\n",
    "\n",
    "### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "\n",
    "#The main tuning parameter is lambda (λ), the regularization parameter. Higher values of λ increase the penalty, leading to more coefficients being shrunk to zero, \n",
    "#which enhances feature selection but can lead to underfitting. Lower values reduce the penalty, which may lead to overfitting.\n",
    "\n",
    "### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "#Lasso Regression itself is linear, but it can be adapted for non-linear problems by combining it with basis functions (like polynomials) or by using kernel methods.\n",
    "#Another approach is to include interaction terms and polynomial features in the dataset before applying Lasso.\n",
    "\n",
    "### Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "#- **Ridge Regression**: Uses L2 regularization (squared sum of coefficients), which shrinks coefficients but doesn't set any to zero.\n",
    "#- **Lasso Regression**: Uses L1 regularization (sum of absolute values of coefficients), which can shrink coefficients to zero, performing feature selection.\n",
    "\n",
    "### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "#Yes, Lasso Regression can handle multicollinearity by shrinking some coefficients to zero, effectively removing correlated predictors and reducing model complexity.\n",
    "\n",
    "### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    "#The optimal value of lambda is usually chosen using cross-validation. The value that minimizes the cross-validation error is selected. \n",
    "#Techniques like k-fold cross-validation or leave-one-out cross-validation are commonly used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faccfdd-6e78-457a-8d72-f72b4075babe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
