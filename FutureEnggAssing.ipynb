{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb72d0be-9d60-42a4-a71b-bf0a3f751f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@!@ What is the Filter method in feature selection, and how does it work\n",
    "\n",
    "#The Filter method in feature selection evaluates features independently of any machine learning algorithm, using statistical measures to rank and select features. Key steps include:\n",
    "\n",
    "#1. **Compute Scores:** Use statistical measures like correlation, mutual information, chi-square, or ANOVA to score each feature.\n",
    "#2. **Rank Features:** Rank features based on their scores.\n",
    "#3. **Select Features:** Choose the top-ranked features according to a threshold or desired number of features. \n",
    "\n",
    "## This method is fast and computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0365c36e-1523-4b3d-aa2f-37dd2a57eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@How does the Wrapper method differ from the Filter method in feature selection?\n",
    "\n",
    "\n",
    "### Filter Method:\n",
    "#- **Independent of Model:** Uses statistical measures to evaluate features.\n",
    "#- **Fast and Efficient:** Computationally less intensive.\n",
    "#- **Statistical Evaluation:** Ranks features based on measures like correlation or chi-square.\n",
    "\n",
    "### Wrapper Method:\n",
    "#- **Dependent on Model:** Evaluates feature subsets by training and testing a model.\n",
    "#- **Performance-Based:** Selects features based on model performance.\n",
    "#- **Computationally Intensive:** Requires multiple iterations of model training, making it slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba6fd2c-f8c4-412c-90eb-bab34c95b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedded feature selection methods incorporate feature selection directly into the model training process. Common techniques include:\n",
    "\n",
    "#1. **Lasso (L1 Regularization):** Adds a penalty to the absolute values of the coefficients, shrinking some to zero, effectively selecting features.\n",
    "\n",
    "#2. **Ridge Regression (L2 Regularization):** Adds a penalty to the square of the coefficients, used to prioritize feature importance rather than selection.\n",
    "\n",
    "#3. **Elastic Net:** Combines L1 and L2 regularization to balance between feature selection and regularization.\n",
    "\n",
    "#4. **Tree-Based Methods:** Decision trees and ensemble methods like Random Forests and Gradient Boosting rank features based on their importance in splitting nodes.\n",
    "\n",
    "#5. **Recursive Feature Elimination (RFE):** Iteratively removes the least important features based on model performance until the optimal subset is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83b0501-c33f-4ff6-a2ef-ada31d55887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@. What are some drawbacks of using the Filter method for feature selection?\n",
    "\n",
    "#Some drawbacks of using the Filter method for feature selection include:\n",
    "\n",
    "#1. **Model Independence:** Does not account for interactions with the specific machine learning model, potentially overlooking model-specific feature importance.\n",
    "\n",
    "#2. **Simplicity:** Relies on basic statistical measures, which might not capture complex relationships between features and the target variable.\n",
    "\n",
    "#3. **Lack of Interaction Consideration:** Evaluates each feature individually, ignoring potential interactions between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7896f4c6-3937-416b-91bc-43e1016c9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ In which situations would you prefer using the Filter method over the Wrapper method for featureselection?\n",
    "\n",
    "#You would prefer using the Filter method over the Wrapper method in situations where:\n",
    "\n",
    "#1. **Large Datasets:** The dataset is large, and computational efficiency is crucial.\n",
    "\n",
    "#2. **Quick Insights:** You need fast, initial insights into feature relevance.\n",
    "\n",
    "#3. **Model-Agnostic Approach:** You want a model-independent feature selection process.\n",
    "\n",
    "#4. **High Dimensionality:** There are many features, and reducing the number before model training is necessary.\n",
    "\n",
    "#5. **Avoid Overfitting:** You're aiming to prevent overfitting by avoiding multiple model training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d440497a-a8c0-4741-ac91-ce2f176f25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different\n",
    "#ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
    "\n",
    "#To choose pertinent attributes for a customer churn predictive model using the Filter Method:\n",
    "\n",
    "#1. **Understand the Data:** Get familiar with the dataset and its features.\n",
    "#2. **Identify Target Variable:** Determine the churn indicator.\n",
    "#3. **Choose Measures:** Select statistical measures like correlation or mutual information.\n",
    "#4. **Compute Scores:** Calculate scores for each feature based on chosen measures.\n",
    "#5. **Rank Features:** Rank features by their scores.\n",
    "#6. **Set Threshold:** Decide on a threshold for feature selection.\n",
    "#7. **Select Features:** Choose top-ranked features meeting the threshold.\n",
    "#8. **Validate:** Validate selected features for model robustness.\n",
    "#9. **Iterate if Needed:** Adjust thresholds or measures if results aren't satisfactory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0ae38-eab7-4906-953c-7b38a65b91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ You are working on a project to predict the price of a house based on its features, such as size, location, and age. You have a limited number of features, and you want to ensure that you select the most importantones for the model. Explain how you would use the Wrapper method to select the best set of features for thepredictor.\n",
    "\n",
    "#To use the Wrapper method for feature selection in predicting house prices:\n",
    "\n",
    "#1. **Define Metric:** Choose evaluation metric (e.g., MSE).\n",
    "#2. **Create Subsets:** Generate feature subsets.\n",
    "#3. **Train Models:** Train models with each subset.\n",
    "#4. **Evaluate Performance:** Assess model performance.\n",
    "#5. **Iterate Selection:** Select best-performing feature subset iteratively.\n",
    "#6. **Cross-Validation:** Validate model using cross-validation.\n",
    "#7. **Final Validation:** Validate selected features on a test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
